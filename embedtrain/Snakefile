import re
from shutil import unpack_archive

from embedtrain.dl_datasets import DataSet
from embedtrain.embed_skels import BODY_EMBED_SKELS, EMBED_SKELS


def cnf(name, val=None):
    if val is None:
        return config[name]
    val = config.setdefault(name, val)
    globals()[name] = val
    return val


# Intermediate dirs
cnf("WORK", "work")
cnf("HAND_H5", WORK + "/hand.h5")
cnf("BODY_H5", WORK + "/body.h5")
cnf("VOCAB", WORK + "/vocab")

MAN_TB_SKEL_NAME_MAP = {}
TRAIN_LOG_SKEL_NAME_MAP = {}
for embed_skel in EMBED_SKELS.keys():
    embed_skel_lower = embed_skel.lower()
    man_tb_dir = cnf(embed_skel + "_MAN_TB", WORK + "/" + embed_skel_lower + "-man-tb")
    MAN_TB_SKEL_NAME_MAP[man_tb_dir] = embed_skel
    train_log_dir = cnf(embed_skel + "_TRAIN_LOG", WORK + "/" + embed_skel_lower + "-train-log")
    TRAIN_LOG_SKEL_NAME_MAP[train_log_dir] = embed_skel


def skel_output_constraint(postfix, skel_names)
    return "|".join(("(^{}$)".format(re.escape(globals()[skel_name + postfix])) for skel_name in skel_names))


DataSet.config_datasets(cnf)


rule all:
    input:
        HAND_H5,
        BODY_H5,
        [globals()[skel_name + "_MAN_TB"] for skel_name in EMBED_SKELS.keys()]


rule ds_download:
    output:
        "{zip_dir}/{basename}"
    wildcard_constraints:
        zip_dir = "|".join((ds.zips for ds in DataSet.by_name.values()))
    params:
        url=lambda wc: DataSet.by_zip[wc.zip_dir].base_map[wc.basename]
    shell:
        "mkdir -p {wildcards.zip_dir} && " +
        "cd {wildcards.zip_dir} && " +
        "wget --retry-connrefused --waitretry=1 --read-timeout=20 " +
        "--timeout=15 -t 64 {params.url}"


def ds_extract_inp(wc):
    ds = DataSet.by_ex[wc.ex_dir]
    return ancient(ds.zips + "/" + ds.bare_map[wc.barename])


rule ds_extract:
    output:
        directory("{ex_dir}/{barename}")
    wildcard_constraints:
        ex_dir = "|".join((ds.ex_dir for ds in DataSet.by_name.values()))
    input:
        ds_extract_inp
    run:
        unpack_archive(input[0], output[0])


rule ds_extracted:
    input:
        lambda wc: [
            ancient(wc.ex_dir + "/" + ds)
            for ds in DataSet.by_ex[wc.ex_dir].bare_map.keys()
        ]
    output:
        touch("{ex_dir}.done")


def runscript(name):
    return f"python {workflow.basedir}/{name}.py"


rule openpose_hands:
    input:
        DataSet.by_name["hand"].ex_dir + ".done"
    output:
        HAND_H5
    shell:
        runscript("prep_images") + " hand" +
        " " + DataSet.by_name["hand"].ex_dir + " " + HAND_H5


rule openpose_body:
    input:
        DataSet.by_name["body"].ex_dir + ".done"
    output:
        BODY_H5
    shell:
        runscript("prep_images") + " body " +
        DataSet.by_name["body"].ex_dir + "/mpii_human_pose_v1/images/ " +
        BODY_H5


rule proj_hands_man:
    input:
        skels = HAND_H5,
        img_base = HAND_DS
    output:
        man_tb = directory(HAND_MAN_TB)
    shell:
        runscript("embed_vis") + " to-tensorboard " +
        "--image-base {input.img_base} {input.skels} {output.man_tb} HAND"

rule proj_body_man:
    input:
        skels = BODY_H5,
        img_base = BODY_DS
    output:
        man_tb = directory("{outdir}")
    wildcard_constraints:
        outdir = skel_output_constraint("_MAN_TB", BODY_EMBED_SKELS.keys())
    params:
        skel_name = lambda wildcards, output: MAN_TB_SKEL_NAME_MAP[output.man_tb]
    shell:
        runscript("embed_vis") + " to-tensorboard " +
        "--image-base {input.img_base} " +
        "--body-labels {input.img_base}/mpii_human_pose_v1_u12_2/mpii_human_pose_v1_u12_2/mpii_human_pose_v1_u12_1.mat " +
        "{input.skels} {output.man_tb} {params.skel_name}"


rule pre_vocab:
    input:
        ds_h5 = lambda wc: HAND_H5 if wc.var == "hand" else BODY_H5
    output:
        vocab_pkl = VOCAB + "/{var}.pkl"
    params:
        skel_name = lambda wildcards, output: wildcards.var.upper()
    shell:
        runscript("prep_vocab") + " {input.ds_h5} {params.skel_name} " +
	"{output.vocab_pkl}"


rule train_pose:
    input:
        skels = lambda wc: \
            HAND_H5 \
	    if TRAIN_LOG_SKEL_NAME_MAP[output.train_log] == "HAND" \
	    else BODY_H5
        vocab_pkl = lambda wc: \
	    VOCAB + "/" + ("hand" \
	    if TRAIN_LOG_SKEL_NAME_MAP[output.train_log] == "HAND" \
	    else "body") + ".pkl"
    output:
        train_log = directory("{outdir}/{loss}-{reduc}-{aug}")
    wildcard_constraints:
        outdir = skel_output_constraint("_TRAIN_LOG", EMBED_SKELS.keys())

    params:
        skel_name = lambda wildcards, output: TRAIN_LOG_SKEL_NAME_MAP[output.train_log]
    shell:
        runscript("train") + " --prep-vocab {input.vocab_pkl} " +
	"{input.skels} {params.skel_name} {outputs.train_log}"

rule pilots_trained:
    input:
        train_log = directory("{outdir}/{var}")
@click.option("--embed-size", type=int, default=64)
@click.option("--loss", type=click.Choice(["nsm", "msl"]), default="nsm")
@click.option("--no-aug", is_flag=True)
