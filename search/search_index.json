{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"SkelShop Documentation This is the documentation for SkelShop . See also the README there for installation and high level CLI usage.","title":"Home"},{"location":"#skelshop-documentation","text":"This is the documentation for SkelShop . See also the README there for installation and high level CLI usage.","title":"SkelShop Documentation"},{"location":"cli/","text":"CLI Reference skelshop Usage: skelshop [OPTIONS] COMMAND [ARGS]... Options: -v, --verbosity LVL Either CRITICAL, ERROR, WARNING, INFO or DEBUG conv Convert a exiting dump from another format into HDF5 format. LEGACY_DUMP is the dump in the old format. OUT is a file path when run with single-zip, otherwise it is the base of a directory tree which will be created during processing. Usage: skelshop conv [OPTIONS] [monolithic-tar|single-zip|ordered-tar] LEGACY_DUMP [OUT] Options: --mode [BODY_25_ALL|BODY_25_HANDS|BODY_25|BODY_135|FACE|BODY_25_FACE] [required] --cores INTEGER Number of cores to use (only for monolithic- tar) --suppress-end-fail / --no-suppress-end-fail --skip-existing / --overwrite-existing drawsticks Output a video with stick figures from pose dump superimposed. Usage: skelshop drawsticks [OPTIONS] H5FN VIDEOIN VIDEOOUT Options: --posetrack / --no-posetrack Whether to convert BODY_25 keypoints to PoseTrack-style keypoints --scale INTEGER --overlay / --no-overlay Whether to draw VIDEOIN below the stick figures or not dump Create a HDF5 pose dump from a video using OpenPose. This command optionally applies steps from the tracking/segmentation pipeline. Usage: skelshop dump [OPTIONS] VIDEO H5FN Options: --mode [BODY_25_ALL|BODY_25_HANDS|BODY_25|BODY_135|FACE|BODY_25_FACE] --model-folder TEXT [required] --debug / --no-debug --shot-csv PATH --pose-matcher-config TEXT --track-conf [lighttrackish|opt_lighttrack|deepsortlike] --track / --no-track --shot-seg [bbskel|csv|none] face Create a HDF5 face dump from a video using dlib. Usage: skelshop face [OPTIONS] VIDEO H5FN Options: --from-skels PATH --start-frame INTEGER --skel-thresh-pool [min|max|mean] --skel-thresh-val FLOAT --batch-size INTEGER --write-bbox / --no-write-bbox --write-chip / --no-write-chip filter Apply tracking to an untracked HDF5 pose dump. Usage: skelshop filter [OPTIONS] H5INFN H5OUTFN Options: --shot-csv PATH --pose-matcher-config TEXT --track-conf [lighttrackish|opt_lighttrack|deepsortlike] --track / --no-track --shot-seg [bbskel|csv|none] --start-frame INTEGER --end-frame INTEGER playsticks Play a video with stick figures from pose dump superimposed. Usage: skelshop playsticks [OPTIONS] VIDEOIN Options: --skel PATH --face PATH --posetrack / --no-posetrack Whether to convert BODY_25 keypoints to PoseTrack-style keypoints --seek-time FLOAT --seek-frame INTEGER --scale INTEGER --paused / --playing stats Output stats about dumps in INPUT_DIR. Usage: skelshop stats [OPTIONS] INPUT_DIR","title":"CLI"},{"location":"cli/#cli-reference","text":"","title":"CLI Reference"},{"location":"cli/#skelshop","text":"Usage: skelshop [OPTIONS] COMMAND [ARGS]... Options: -v, --verbosity LVL Either CRITICAL, ERROR, WARNING, INFO or DEBUG","title":"skelshop"},{"location":"cli/#conv","text":"Convert a exiting dump from another format into HDF5 format. LEGACY_DUMP is the dump in the old format. OUT is a file path when run with single-zip, otherwise it is the base of a directory tree which will be created during processing. Usage: skelshop conv [OPTIONS] [monolithic-tar|single-zip|ordered-tar] LEGACY_DUMP [OUT] Options: --mode [BODY_25_ALL|BODY_25_HANDS|BODY_25|BODY_135|FACE|BODY_25_FACE] [required] --cores INTEGER Number of cores to use (only for monolithic- tar) --suppress-end-fail / --no-suppress-end-fail --skip-existing / --overwrite-existing","title":"conv"},{"location":"cli/#drawsticks","text":"Output a video with stick figures from pose dump superimposed. Usage: skelshop drawsticks [OPTIONS] H5FN VIDEOIN VIDEOOUT Options: --posetrack / --no-posetrack Whether to convert BODY_25 keypoints to PoseTrack-style keypoints --scale INTEGER --overlay / --no-overlay Whether to draw VIDEOIN below the stick figures or not","title":"drawsticks"},{"location":"cli/#dump","text":"Create a HDF5 pose dump from a video using OpenPose. This command optionally applies steps from the tracking/segmentation pipeline. Usage: skelshop dump [OPTIONS] VIDEO H5FN Options: --mode [BODY_25_ALL|BODY_25_HANDS|BODY_25|BODY_135|FACE|BODY_25_FACE] --model-folder TEXT [required] --debug / --no-debug --shot-csv PATH --pose-matcher-config TEXT --track-conf [lighttrackish|opt_lighttrack|deepsortlike] --track / --no-track --shot-seg [bbskel|csv|none]","title":"dump"},{"location":"cli/#face","text":"Create a HDF5 face dump from a video using dlib. Usage: skelshop face [OPTIONS] VIDEO H5FN Options: --from-skels PATH --start-frame INTEGER --skel-thresh-pool [min|max|mean] --skel-thresh-val FLOAT --batch-size INTEGER --write-bbox / --no-write-bbox --write-chip / --no-write-chip","title":"face"},{"location":"cli/#filter","text":"Apply tracking to an untracked HDF5 pose dump. Usage: skelshop filter [OPTIONS] H5INFN H5OUTFN Options: --shot-csv PATH --pose-matcher-config TEXT --track-conf [lighttrackish|opt_lighttrack|deepsortlike] --track / --no-track --shot-seg [bbskel|csv|none] --start-frame INTEGER --end-frame INTEGER","title":"filter"},{"location":"cli/#playsticks","text":"Play a video with stick figures from pose dump superimposed. Usage: skelshop playsticks [OPTIONS] VIDEOIN Options: --skel PATH --face PATH --posetrack / --no-posetrack Whether to convert BODY_25 keypoints to PoseTrack-style keypoints --seek-time FLOAT --seek-frame INTEGER --scale INTEGER --paused / --playing","title":"playsticks"},{"location":"cli/#stats","text":"Output stats about dumps in INPUT_DIR. Usage: skelshop stats [OPTIONS] INPUT_DIR","title":"stats"},{"location":"pipeline-internals/","text":"The stage interface is quite simple. Each stage acts as an iterator, typically yielding some kind of pose bundle. A pose bundle is an iterator of skeletons, either with ids or not depending on whether it has been tracked. Each stage inherits from the PipelineStageBase abstract base class which includes also send_back to send back events to earlier stages in the pipeline. skelshop.pipebase.PipelineStageBase The abstract base class for a pipeline stage. __next__ ( self ) special Get the payload for the next frame Source code in skelshop/pipebase.py @abstractmethod def __next__ ( self ): \"\"\" Get the payload for the next frame \"\"\" ... send_back ( self , name , * args , ** kwargs ) Send a message back down the pipeline by calling a method with name , *args , and `*kwargs Source code in skelshop/pipebase.py def send_back ( self , name : str , * args , ** kwargs ): \"\"\" Send a message back down the pipeline by calling a method with `name`, `*args`, and `*kwargs \"\"\" meth = getattr ( self , name , None ) if meth is not None : meth ( * args , ** kwargs ) return if self . prev is not None : self . prev . send_back ( name , * args , ** kwargs ) Events types in use through send_back Currently cut event is sent back by any shot segmentation stage to the tracking stage, so that tracking can be reset. Each stage is free to deal with events as it wishes, e.g. a tracking stage attempting to track across shots could react differently to this event. A rewind event can be sent back so that a RewindStage will reverse a given number of frames in its buffer. Note that you must arrange for a RewindStage to be placed into the pipeline.","title":"Pipeline internals"},{"location":"pipeline-internals/#skelshop.pipebase.PipelineStageBase","text":"The abstract base class for a pipeline stage.","title":"PipelineStageBase"},{"location":"pipeline-internals/#skelshop.pipebase.PipelineStageBase.__next__","text":"Get the payload for the next frame Source code in skelshop/pipebase.py @abstractmethod def __next__ ( self ): \"\"\" Get the payload for the next frame \"\"\" ...","title":"__next__()"},{"location":"pipeline-internals/#skelshop.pipebase.PipelineStageBase.send_back","text":"Send a message back down the pipeline by calling a method with name , *args , and `*kwargs Source code in skelshop/pipebase.py def send_back ( self , name : str , * args , ** kwargs ): \"\"\" Send a message back down the pipeline by calling a method with `name`, `*args`, and `*kwargs \"\"\" meth = getattr ( self , name , None ) if meth is not None : meth ( * args , ** kwargs ) return if self . prev is not None : self . prev . send_back ( name , * args , ** kwargs )","title":"send_back()"},{"location":"pipeline-internals/#events-types-in-use-through-send_back","text":"Currently cut event is sent back by any shot segmentation stage to the tracking stage, so that tracking can be reset. Each stage is free to deal with events as it wishes, e.g. a tracking stage attempting to track across shots could react differently to this event. A rewind event can be sent back so that a RewindStage will reverse a given number of frames in its buffer. Note that you must arrange for a RewindStage to be placed into the pipeline.","title":"Events types in use through send_back"},{"location":"tracking/","text":"The tracker is a stage that each frame takes an unordered bundle of poses and gives them IDs. skelshop.bbtrack.TrackStage A pipeline stage wrapping the skelshop.track.PoseTrack generic approach to distance-based tracking. Internally it uses the following class, which implements a generic approach to online pose tracking: skelshop.track.track.PoseTrack Performs generic distance-based pose tracking. __init__ ( self , spec ) special Takes a TrackingSpec and constructs the corresponding tracking algorithm. Source code in skelshop/track/track.py def __init__ ( self , spec : TrackingSpec ): \"\"\" Takes a TrackingSpec and constructs the corresponding tracking algorithm. \"\"\" self . next_id = 0 self . prev_tracked : FrameBuf = ( collections . deque ( maxlen = spec . prev_frame_buf_size ) ) self . spec = spec Which is in turn configured using a: skelshop.track.spec.TrackingSpec dataclass A domain specific language for threshold distance-based style tracking. Candidate poses are first filtered using cand_filter and then procedure is executed to decide how to assign the candidates. Several configurations are given in: skelshop.track.confs.CONFS A dictionary of ready-made tracking specs Attributes: Name Type Description \"lighttrackish\" TrackingSpec A LightTrack-like algoirhtm using greedy matching \"opt_lighttrack\" TrackingSpec A LightTrack-like algorithm which attempts to make optimal matches \"deepsortlike\" TrackingSpec A DeepSort-like algorithm (currently missing Kalman filtering) There are references to two systems in the name: LightTrack 1 and DeepSort 2 . The configurations are inspired by these, but not exact implementations. Looking at the implementations in skelshop.track.confs.CONFS is a good starting point for adding new configurations, or extending the tracking, e.g. with a new approach to reidentification. Guanghan Ning, Heng Huang (2019) LightTrack: A Generic Framework for Online Top-Down Human Pose Tracking https://arxiv.org/abs/1905.02822 \u21a9 Nicolai Wojke, Alex Bewley, Dietrich Paulus (2017) Simple Online and Realtime Tracking with a Deep Association Metric https://arxiv.org/abs/1703.07402 \u21a9","title":"Tracking"},{"location":"tracking/#skelshop.bbtrack.TrackStage","text":"A pipeline stage wrapping the skelshop.track.PoseTrack generic approach to distance-based tracking. Internally it uses the following class, which implements a generic approach to online pose tracking:","title":"TrackStage"},{"location":"tracking/#skelshop.track.track.PoseTrack","text":"Performs generic distance-based pose tracking.","title":"PoseTrack"},{"location":"tracking/#skelshop.track.track.PoseTrack.__init__","text":"Takes a TrackingSpec and constructs the corresponding tracking algorithm. Source code in skelshop/track/track.py def __init__ ( self , spec : TrackingSpec ): \"\"\" Takes a TrackingSpec and constructs the corresponding tracking algorithm. \"\"\" self . next_id = 0 self . prev_tracked : FrameBuf = ( collections . deque ( maxlen = spec . prev_frame_buf_size ) ) self . spec = spec Which is in turn configured using a:","title":"__init__()"},{"location":"tracking/#skelshop.track.spec.TrackingSpec","text":"A domain specific language for threshold distance-based style tracking. Candidate poses are first filtered using cand_filter and then procedure is executed to decide how to assign the candidates. Several configurations are given in:","title":"TrackingSpec"},{"location":"tracking/#skelshop.track.confs.CONFS","text":"A dictionary of ready-made tracking specs Attributes: Name Type Description \"lighttrackish\" TrackingSpec A LightTrack-like algoirhtm using greedy matching \"opt_lighttrack\" TrackingSpec A LightTrack-like algorithm which attempts to make optimal matches \"deepsortlike\" TrackingSpec A DeepSort-like algorithm (currently missing Kalman filtering) There are references to two systems in the name: LightTrack 1 and DeepSort 2 . The configurations are inspired by these, but not exact implementations. Looking at the implementations in skelshop.track.confs.CONFS is a good starting point for adding new configurations, or extending the tracking, e.g. with a new approach to reidentification. Guanghan Ning, Heng Huang (2019) LightTrack: A Generic Framework for Online Top-Down Human Pose Tracking https://arxiv.org/abs/1905.02822 \u21a9 Nicolai Wojke, Alex Bewley, Dietrich Paulus (2017) Simple Online and Realtime Tracking with a Deep Association Metric https://arxiv.org/abs/1703.07402 \u21a9","title":"CONFS"}]}